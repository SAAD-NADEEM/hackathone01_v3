---
title: Glossary
description: Definitions of key terms used throughout the Physical AI and Humanoid Robotics educational resource
keywords: [glossary, definitions, robotics, AI, terminology]
sidebar_position: 1
---

# Glossary

## A

### Action Space
The set of all possible actions that an agent can take in an environment, particularly in reinforcement learning contexts.

### Affordance
The possibility of an action on an object or environment as perceived by an agent; what the environment offers or affords the agent.

## B

### Behavior Tree
A hierarchical structure used to organize and control the execution of tasks in robotics and AI, providing a more flexible alternative to finite state machines.

## C

### Cognitive Architecture
A framework for designing intelligent agents that incorporates models of perception, action, memory, and reasoning.

### Control Loop
The fundamental mechanism in robotics that continuously reads sensor inputs, processes them according to a control algorithm, and produces actuator outputs.

## D

### Digital Twin
A virtual representation of a physical system that mirrors its real-world counterpart in real time, enabling simulation and prediction of system behavior.

### Dexterity
The skill in performing tasks that require fine motor control, particularly in the context of robotic manipulation.

## E

### Embodied AI
Artificial intelligence systems that interact with the physical world through a body or robotic platform, learning from and adapting to their environment.

## G

### Grounding
The process of connecting symbolic representations or language to perceptual experience and physical reality.

## H

### Human-Robot Interaction (HRI)
The study of interactions between humans and robots and the design of robots that can interact with humans in a natural and safe manner.

## I

### Inverse Kinematics
The mathematical process of determining the joint parameters needed to position a robot's end-effector at a desired location and orientation.

## K

### Kinematics
The study of motion without considering the forces that cause the motion, essential for robot motion planning.

## L

### Latent Space
A lower-dimensional space that captures the essential features of high-dimensional data, often used in machine learning models.

## M

### Manipulation
The ability of a robot to purposefully control objects in its environment, typically using robotic arms and hands.

## N

### Navigation
The process by which a robot determines and follows a path from one location to another in its environment.

## P

### Perception Pipeline
The sequence of computational processes that transform raw sensor data into meaningful information for the robot's decision-making systems.

### Planning
The process of determining a sequence of actions to achieve a goal, including motion planning, task planning, and path planning.

## R

### Reinforcement Learning
A type of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties.

### Robot Operating System (ROS)
A flexible framework for writing robot software that provides services designed for a heterogeneous computer cluster.

### ROS 2
The second generation of the Robot Operating System, designed for production environments with improved security, real-time support, and better architecture.

## S

### Sensor Fusion
The process of combining sensory data or data derived from disparate sources to achieve better information than could be achieved by using a single sensor alone.

### SLAM (Simultaneous Localization and Mapping)
The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

## V

### Vision-Language-Action (VLA)
A multimodal AI approach that combines visual perception, language understanding, and action execution in a unified system.

## W

### Workspace
The volume of space that a robot manipulator can reach with its end-effector.

## Y

### Yaw
The rotation of a robot or object around its vertical axis.